df.train <- df.small[trainIndex, ]
df.test <- df.small[-trainIndex, ]
# Fit the model
model <- glm(cat ~ x, data = df.train, family = binomial)
# Summarize the model
summary(model)
# Make predictions
prob <- predict(model, newdata = df.test)
predict.class <- ifelse(prob > .05, "high", "low")
acc[i] <- mean(predict.class == df.test$cat)
}
plot(y = acc, x = r)
library('MASS')
library('caret')
samples = 5*160
r = c(seq(from = 0, to = 1, by = 0.05))
acc = numeric(length = length(r))
for(i in 1:length(r)){
df = mvrnorm(n=samples, mu=c(0, 0), Sigma=matrix(c(1, r[i], r[i], 1), nrow=2), empirical=TRUE)
df <- as.data.frame(df)
names(df) <- c("x", "y")
cor(df$x, df$y)
qs <- quantile(df[, 2], probs = c(0.15, 0.85))
df$cat <- cut(df$y,
breaks=c(-Inf, -1, 1, Inf),
labels=c("low","middle","high"))
df.small <- df[df$cat != "middle", ]
trainIndex <- createDataPartition(df.small$cat, p = .8,
list = FALSE,
times = 1)
df.train <- df.small[trainIndex, ]
df.test <- df.small[-trainIndex, ]
# Fit the model
model <- glm(cat ~ x, data = df.train, family = binomial)
# Summarize the model
summary(model)
# Make predictions
prob <- predict(model, newdata = df.test)
predict.class <- ifelse(prob > .05, "high", "low")
acc[i] <- mean(predict.class == df.test$cat)
}
plot(y = acc, x = r)
library('MASS')
library('caret')
samples = 5*160
r = c(seq(from = 0, to = 1, by = 0.05))
acc = numeric(length = length(r))
for(i in 1:length(r)){
df = mvrnorm(n=samples, mu=c(0, 0), Sigma=matrix(c(1, r[i], r[i], 1), nrow=2), empirical=TRUE)
df <- as.data.frame(df)
names(df) <- c("x", "y")
cor(df$x, df$y)
qs <- quantile(df[, 2], probs = c(0.15, 0.85))
df$cat <- cut(df$y,
breaks=c(-Inf, -1, 1, Inf),
labels=c("low","middle","high"))
df.small <- df[df$cat != "middle", ]
trainIndex <- createDataPartition(df.small$cat, p = .8,
list = FALSE,
times = 1)
df.train <- df.small[trainIndex, ]
df.test <- df.small[-trainIndex, ]
# Fit the model
model <- glm(cat ~ x, data = df.train, family = binomial)
# Summarize the model
summary(model)
# Make predictions
prob <- predict(model, newdata = df.test)
predict.class <- ifelse(prob > .05, "high", "low")
acc[i] <- mean(predict.class == df.test$cat)
}
plot(y = acc, x = r)
library('MASS')
library('caret')
samples = 5*160
r = c(seq(from = 0, to = 1, by = 0.05))
acc = numeric(length = length(r))
for(i in 1:length(r)){
df = mvrnorm(n=samples, mu=c(0, 0), Sigma=matrix(c(1, r[i], r[i], 1), nrow=2), empirical=TRUE)
df <- as.data.frame(df)
names(df) <- c("x", "y")
cor(df$x, df$y)
qs <- quantile(df[, 2], probs = c(0.15, 0.85))
df$cat <- cut(df$y,
breaks=c(-Inf, -1, 1, Inf),
labels=c("low","middle","high"))
df.small <- df[df$cat != "middle", ]
trainIndex <- createDataPartition(df.small$cat, p = .8,
list = FALSE,
times = 1)
df.train <- df.small[trainIndex, ]
df.test <- df.small[-trainIndex, ]
# Fit the model
model <- glm(cat ~ x, data = df.train, family = binomial)
# Summarize the model
summary(model)
# Make predictions
prob <- predict(model, newdata = df.test)
predict.class <- ifelse(prob > .05, "high", "low")
acc[i] <- mean(predict.class == df.test$cat)
}
plot(y = acc, x = r)
library('MASS')
library('caret')
samples = 5*160
r = c(seq(from = 0, to = 1, by = 0.05))
acc = numeric(length = length(r))
for(i in 1:length(r)){
df = mvrnorm(n=samples, mu=c(0, 0), Sigma=matrix(c(1, r[i], r[i], 1), nrow=2), empirical=TRUE)
df <- as.data.frame(df)
names(df) <- c("x", "y")
cor(df$x, df$y)
qs <- quantile(df[, 2], probs = c(0.15, 0.85))
df$cat <- cut(df$y,
breaks=c(-Inf, -1, 1, Inf),
labels=c("low","middle","high"))
df.small <- df[df$cat != "middle", ]
trainIndex <- createDataPartition(df.small$cat, p = .8,
list = FALSE,
times = 1)
df.train <- df.small[trainIndex, ]
df.test <- df.small[-trainIndex, ]
# Fit the model
model <- glm(cat ~ x, data = df.train, family = binomial)
# Summarize the model
summary(model)
# Make predictions
prob <- predict(model, newdata = df.test)
predict.class <- ifelse(prob > .05, "high", "low")
acc[i] <- mean(predict.class == df.test$cat)
}
plot(y = acc, x = r)
library('MASS')
library('caret')
samples = 5*160
r = c(seq(from = 0, to = 1, by = 0.05))
acc = numeric(length = length(r))
for(i in 1:length(r)){
df = mvrnorm(n=samples, mu=c(0, 0), Sigma=matrix(c(1, r[i], r[i], 1), nrow=2), empirical=TRUE)
df <- as.data.frame(df)
names(df) <- c("x", "y")
cor(df$x, df$y)
qs <- quantile(df[, 2], probs = c(0.15, 0.85))
df$cat <- cut(df$y,
breaks=c(-Inf, -1, 1, Inf),
labels=c("low","middle","high"))
df.small <- df[df$cat != "middle", ]
trainIndex <- createDataPartition(df.small$cat, p = .8,
list = FALSE,
times = 1)
df.train <- df.small[trainIndex, ]
df.test <- df.small[-trainIndex, ]
# Fit the model
model <- glm(cat ~ x, data = df.train, family = binomial)
# Summarize the model
summary(model)
# Make predictions
prob <- predict(model, newdata = df.test)
predict.class <- ifelse(prob > .05, "high", "low")
acc[i] <- mean(predict.class == df.test$cat)
}
plot(y = acc, x = r)
library('MASS')
library('caret')
samples = 5*160
r = c(seq(from = 0, to = 1, by = 0.05))
acc = numeric(length = length(r))
for(i in 1:length(r)){
df = mvrnorm(n=samples, mu=c(0, 0), Sigma=matrix(c(1, r[i], r[i], 1), nrow=2), empirical=TRUE)
df <- as.data.frame(df)
names(df) <- c("x", "y")
cor(df$x, df$y)
qs <- quantile(df[, 2], probs = c(0.15, 0.85))
df$cat <- cut(df$y,
breaks=c(-Inf, -1, 1, Inf),
labels=c("low","middle","high"))
df.small <- df[df$cat != "middle", ]
trainIndex <- createDataPartition(df.small$cat, p = .8,
list = FALSE,
times = 1)
df.train <- df.small[trainIndex, ]
df.test <- df.small[-trainIndex, ]
# Fit the model
model <- glm(cat ~ x, data = df.train, family = binomial)
# Summarize the model
summary(model)
# Make predictions
prob <- predict(model, newdata = df.test)
predict.class <- ifelse(prob > .05, "high", "low")
acc[i] <- mean(predict.class == df.test$cat)
}
plot(y = acc, x = r)
install.packages("lavaan")
lavaan:summary
library("lavaan")
?lavaan::`summary,lavaan-method`
library(psychometric) # load package with function
CIr(r=.13, n = 425, level = .95)
CIr(r=.04, n = 448, level = .95)
install.packages("here")
library("foreign")
shiny::runApp('C:/Users/mauri/OneDrive/Arbeit/Projekte/OxyReceptor/OXTRmeth_analyses/OXTR-shinyApp')
runApp('C:/Users/mauri/OneDrive/Arbeit/Projekte/OxyReceptor/OXTRmeth_analyses/OXTR-shinyApp')
shiny::runApp('C:/Users/mauri/OneDrive/Arbeit/Projekte/OxyReceptor/OXTRmeth_analyses/OXTR-shinyApp')
runApp('C:/Users/mauri/OneDrive/Arbeit/Projekte/OxyReceptor/OXTRmeth_analyses/OXTR-shinyApp')
runApp('C:/Users/mauri/OneDrive/Arbeit/Projekte/OxyReceptor/OXTRmeth_analyses/OXTR-shinyApp')
runApp('C:/Users/mauri/OneDrive/Arbeit/Projekte/OxyReceptor/OXTRmeth_analyses/OXTR-shinyApp')
df <- read_excel("data/OXTR_table.xlsx")
df <- df[!is.na(df$Effect_CTQ), ]
df$`chr3 position` <- as.character(df$`chr3 position`)
df <- read_excel("data/OXTR_table.xlsx")
setwd("C:\Users\mauri\OneDrive\Arbeit\Projekte\OxyReceptor\OXTRmeth_analyses\OXTR-shinyApp")
setwd("C:/Users/mauri/OneDrive/Arbeit/Projekte/OxyReceptor/OXTRmeth_analyses/OXTR-shinyApp")
df <- read_excel("data/OXTR_table.xlsx")
df <- df[!is.na(df$Effect_CTQ), ]
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
input$MT2 <- T
input <- 0
input$MT2 <- T
MT2Test <- T
ifelse(MT2Test == T & df$MT2 == T, T, F)
MT2Test <- F
ifelse(MT2Test == T & df$MT2 == T,
T,
F)
names(df)
MT2Test <- F
TransTest <- T
ifelse(MT2Test == T & df$MT2 == T,
T,
ifelse(
TransTest == T & df$Exon3_Translational == T,
T,
F
))
MT2Test <- T
TransTest <- F
ifelse(MT2Test == T & df$MT2 == T,
T,
ifelse(
TransTest == T & df$Exon3_Translational == T,
T,
F
))
MT2Test <- F
TransTest <- F
ifelse(MT2Test == T & df$MT2 == T,
T,
ifelse(
TransTest == T & df$Exon3_Translational == T,
T,
ifelse(
MT2Test == F & TransTest == F,
T,
F
)
))
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
install.packages("DT")
install.packages("DT")
library("DT")
runApp()
runApp()
runApp()
?renderDataTable
?DT::renderDataTable
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
?tabPanel
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
?p
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
df$`Infinium 450K`
is.na(df$`Infinium 450K`)
is.na(df$`Infinium 450K`) == F
is.na(df$`Infinium 450K`) == F
t = T
t == T & is.na(df$`Infinium 450K`) == F
runApp()
nchar(df$`Infinium 450K` > 2)
nchar(df$`Infinium 450K`) > 2
runApp()
df[t == T & nchar(df$`Infinium 450K`) > 2, ]
runApp()
runApp()
runApp()
!is.na(df$`Infinium 450K`)
runApp()
runApp()
test == T
test = T
runApp()
runApp()
runApp()
install.packages("rsconnect")
rsconnect::setAccountInfo(name='msicorello', token='6E092B704FC286AAF0CACF9A2AF595DD', secret='dfeBvEKBrWtuE0bttvPLueQs93leSMPQMBLladbI')
rsconnect::deployApp('C:/Users/mauri/OneDrive/Arbeit/Projekte/OxyReceptor/OXTRmeth_analyses/OXTR-shinyApp')
shiny::runApp()
shiny::runApp()
runApp()
shiny::runApp()
runApp()
library("shiny")
# Histogram of the Old Faithful Geyser Data ----
# with requested number of bins
# This expression that generates a histogram is wrapped in a call
# to renderPlot to indicate that:
#
# 1. It is "reactive" and therefore should be automatically
#    re-executed when inputs (input$bins) change
# 2. Its output type is a plot
output$distPlot <- renderPlot({
x    <- faithful$waiting
bins <- seq(min(x), max(x), length.out = input$bins + 1)
hist(x, breaks = bins, col = "#007bc2", border = "white",
xlab = "Waiting time to next eruption (in mins)",
main = "Histogram of waiting times")
})
runExample("01_hello")
library(bslib)
library("shiny")
library(shiny)
library(bslib)
# Define UI for app that draws a histogram ----
ui <- page_sidebar(
# App title ----
title = "Hello Shiny!",
# Sidebar panel for inputs ----
sidebar = sidebar(
# Input: Slider for the number of bins ----
sliderInput(
inputId = "bins",
label = "Number of bins:",
min = 1,
max = 50,
value = 30
)
),
# Output: Histogram ----
plotOutput(outputId = "distPlot")
)
# Define server logic required to draw a histogram ----
server <- function(input, output) {
# Histogram of the Old Faithful Geyser Data ----
# with requested number of bins
# This expression that generates a histogram is wrapped in a call
# to renderPlot to indicate that:
#
# 1. It is "reactive" and therefore should be automatically
#    re-executed when inputs (input$bins) change
# 2. Its output type is a plot
output$distPlot <- renderPlot({
x    <- faithful$waiting
bins <- seq(min(x), max(x), length.out = input$bins + 1)
hist(x, breaks = bins, col = "#007bc2", border = "white",
xlab = "Waiting time to next eruption (in mins)",
main = "Histogram of waiting times")
})
}
shinyApp(ui = ui, server = server)
wd <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(wd)
if(!require("pacman")){install.packages("pacman")}
p_load(here, R.matlab, stringr, plyr, ggplot2, caret, BayesFactor, party, cowplot, sjstats, pwr, readxl, grid, psychometric, devEMF, lme4, svglite)
#####################################
# helper functions
# checks whether file exists before saving [csv (default) or rds allowed]
checkNsave <- function(object, outputPath, extension = "csv"){
if(!file.exists(outputPath)){
if(extension == "rds"){
saveRDS(object, outputPath)
}else if (extension == "csv"){
write.csv(object, outputPath, row.names = FALSE)
}
}else{
warning("File already exists in folder")
}
}
#####################################
# read data
filenames <- list.files(here::here(wd, "Results", "Multiverse_Loop"))
# number of repeats and folds
exampleFile <- readMat(here::here(wd, "Results", "Multiverse_Loop", filenames[1]))
nRepeats <- length(exampleFile$fullOutputs)
nFolds <- exampleFile$fullOutputs[[1]][[3]]
# loop to load data into df
df <- as.data.frame(matrix(nrow = 0, ncol = 11))
for(i in 1:length(filenames)){
# prepare filename
filename <- filenames[i]
filename_noExt <- substr(filename, 1, nchar(filename)-4)
if(substr(filename_noExt, 1, 11) == "ER_LookDiff"){filename_noExt <- str_replace(filename_noExt, "ER_LookDiff", "ERLookDiff")}
filename_split <- str_split(filename_noExt, "_", simplify = T)
# load file
modelResults <- readMat(here::here(wd, "Results", "Multiverse_Loop", filename))
for(j in 1:nRepeats){
resultRows <- cbind(matrix(filename_split, nrow=nFolds, ncol=length(filename_split), byrow=TRUE), modelResults$fullOutputs[[j]][[5]], filename_noExt)
df <- rbind(df, resultRows)
}
}
#####################################
# preprocess data
names(df) <- c("outcome", "data", "contrast", "trainsVsFull", "masking", "rescale", "cv", "algorithm", "cvCorr", "optHyperPar", "modelDescr")
df$cvCorr <- as.numeric(df$cvCorr)
df$data <- ifelse(df$data == "Faces-PFA", "PFA", df$data)
# calculate mean correlation per model (including fisher z transformation)
df <- ddply(df, c("outcome", "data", "contrast", "trainsVsFull", "masking", "rescale", "cv", "algorithm"), transform, meanCorr = tanh(mean(atanh(cvCorr))))
#####################################
# plot data
################
# multiverse plots
hist(df$cvCorr)
dfMean <- unique(df[, -which(names(df) == "cvCorr" | names(df) == "optHyperPar")])
names(dfMean)[which(names(dfMean) == "meanCorr")] <- "cvCorr"
plotMultiverse <- function(outcome){
ggplot(data = df[df$outcome == outcome, ], aes(x = reorder(modelDescr, -cvCorr), y = cvCorr)) +
geom_point(colour = "lightgrey") +
geom_point(data = dfMean[dfMean$outcome == outcome, ]) +
geom_hline(yintercept = mean(df[df$outcome == outcome, "cvCorr"]), linetype = "dashed") +
theme_classic() +
theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust=1)) +
ggtitle(outcome) + xlab("Model") + ylab("Pattern-Outcome Correlation")
}
plotMultiverse("ERLookDiff")
plotMultiverse("BDI")
plotMultiverse("neoN")
plotMultiverse("NA")
plotMultiverse("PA")
plotMultiverse("STAI")
plotMultiverse("neoN1")
plotMultiverse("neoN2")
plotMultiverse("neoN6")
################
# make list of best models per construct based on training data
dfMean$trainsVsFull <- ifelse(dfMean$outcome == "NEONother" | dfMean$outcome == "NEONX", "AHAB", dfMean$trainsVsFull)
# first stage neuroticism model set
dfMean[dfMean$outcome == "neoN" & dfMean$algorithm == "pls" & dfMean$trainsVsFull == "train", ]
ddply(dfMean[dfMean$outcome == "neoN" & dfMean$algorithm == "pls" & dfMean$trainsVsFull == "train", ], .(outcome), function(x) x[which.max(x$cvCorr),])
# second stage neuroticism model set
df_2ndstage <-  dfMean[dfMean$trainsVsFull != "full" &
dfMean$algorithm != "rf" &
dfMean$outcome %in% c("neoN", "neoN1", "neoN2", "neoN3", "neoN4", "neoN5", "neoN6"), ]
df_2ndstage[df_2ndstage$cvCorr == max(df_2ndstage$cvCorr), ]
ddply(dfMean[dfMean$trainsVsFull != "full" &
dfMean$algorithm != "rf" &
dfMean$outcome %in% c("neoN", "neoN1", "neoN2", "neoN3", "neoN4", "neoN5", "neoN6"), ], .(outcome), function(x) x[which.max(x$cvCorr),])
# all models
ddply(dfMean, .(outcome), function(x) x[which.max(x$cvCorr),])
if(!file.exists(here::here("Results", "Tables", "bestTrainModels.csv"))){
write.csv(ddply(dfMean[dfMean$trainsVsFull != "full", ], .(outcome), function(x) x[which.max(x$cvCorr),]),
here::here("Results", "Tables", "bestTrainModels.csv"),
row.names = FALSE)
}else{
warning("File already exists in folder")
}
df_design
names(df)
df_design <- df[, -c(5, 7, 10, 11, 12)]
df_design$contrast <- ifelse(df_design$contrast == "LookNeg-vs-Baseline" | df_design$contrast == "Faces-vs-Baseline", "implBaseline", "controlCond")
df_design$trainsVsFull <- ifelse(df_design$outcome == "NEONother" | df_design$outcome == "NEONX", "AHAB", df_design$trainsVsFull)
df_design[,1:6] <- data.frame(unclass(df_design[,1:6]), stringsAsFactors = TRUE)
head(df_design)
?write.csv
write.csv(df_design, here::here("NDesignShinyApp", "dfDesign.csv"), row.names = FALSE)
df_design
write.csv(df_design, here::here("NDesignShinyApp", "dfDesign.csv"), row.names = FALSE)
write.csv(df_design, here::here(wd, "NDesignShinyApp", "dfDesign.csv"), row.names = FALSE)
